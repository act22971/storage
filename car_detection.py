import subprocess as sp
import cv2
import numpy as np
from ultralytics import YOLO
import os
import time
import torch

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² GPU à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ðŸ–¥ï¸ à¹ƒà¸Šà¹‰à¸­à¸¸à¸›à¸à¸£à¸“à¹Œ: {device}")

# à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥ YOLOv8 à¸—à¸µà¹ˆà¹à¸¡à¹ˆà¸™à¸¢à¸³à¸‚à¸¶à¹‰à¸™
model = YOLO('yolov8s.pt').to(device)

# RTSP URL
RTSP_URL = 'rtsp://admin:NT2%40admin@ntcctvptn.totddns.com:64780/cam/realmonitor?channel=1&subtype=0'

# à¸„à¸§à¸²à¸¡à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸‚à¸­à¸‡à¸à¸¥à¹‰à¸­à¸‡
FRAME_WIDTH, FRAME_HEIGHT = 1280, 720

# à¸§à¸±à¸•à¸–à¸¸à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š
TARGET_CLASSES = {'car', 'motorcycle', 'person'}

def get_color_by_class(class_name):
    color_map = {#BGR
        'person': (0, 128, 255),       # à¹à¸”à¸‡
        'car': (0, 255, 0),          # à¹€à¸‚à¸µà¸¢à¸§
        'motorcycle': (255, 0, 0), # à¸ªà¹‰à¸¡à¸­à¹ˆà¸­à¸™
    }
    return color_map.get(class_name, (255, 255, 255))  # à¸ªà¸µà¸‚à¸²à¸§à¹€à¸›à¹‡à¸™à¸„à¹ˆà¸² default


def ffmpeg_pipe(url, width=1280, height=720):
    cmd = [
        'ffmpeg',
        '-rtsp_transport', 'tcp',
        '-i', url,
        '-loglevel', 'quiet',
        '-an',
        '-f', 'rawvideo',
        '-pix_fmt', 'bgr24',
        '-s', f"{width}x{height}",
        '-vcodec', 'rawvideo',
        '-'
    ]
    return sp.Popen(cmd, stdout=sp.PIPE, bufsize=10**8)

def preprocess_frame(frame):
    """à¹€à¸žà¸´à¹ˆà¸¡ contrast à¹à¸¥à¸°à¸›à¸£à¸±à¸šà¹à¸ªà¸‡"""
    # frame = cv2.GaussianBlur(frame, (3, 3), 0)  # à¹ƒà¸Šà¹‰à¸–à¹‰à¸²à¸à¸¥à¹‰à¸­à¸‡ noisy
    return cv2.convertScaleAbs(frame, alpha=1.3, beta=20)

def main():
    print("ðŸš€ à¹€à¸£à¸´à¹ˆà¸¡à¸ªà¸•à¸£à¸µà¸¡ RTSP à¹à¸¥à¸°à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ YOLOv8 ...")
    pipe = ffmpeg_pipe(RTSP_URL, FRAME_WIDTH, FRAME_HEIGHT)
    track_memory = {}
    cv2.namedWindow("YOLOv8 RTSP", cv2.WINDOW_NORMAL)

    try:
        while True:
            raw_frame = pipe.stdout.read(FRAME_WIDTH * FRAME_HEIGHT * 3)
            if len(raw_frame) != FRAME_WIDTH * FRAME_HEIGHT * 3:
                print("âš ï¸ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¸„à¸£à¸š â€” à¸à¸¥à¹‰à¸­à¸‡à¸­à¸²à¸ˆà¸«à¸¥à¸¸à¸”à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­")
                break

            frame = np.frombuffer(raw_frame, np.uint8).reshape((FRAME_HEIGHT, FRAME_WIDTH, 3))
            frame = preprocess_frame(frame)

            results = model.track(
            frame,
            persist=True,
            tracker="bytetrack.yaml",
            imgsz=1280,
            conf=0.2,
            iou=0.45,
            agnostic_nms=True,
            device=device  # à¹ƒà¸«à¹‰à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¸§à¹ˆà¸²à¹ƒà¸Šà¹‰ GPU à¸–à¹‰à¸²à¸¡à¸µ
            )


            current_time = time.time()
            names = model.names

            for result in results:
                if result.boxes is not None and len(result.boxes) > 0:
                    boxes = result.boxes
                    cls_ids = boxes.cls.cpu().numpy().astype(int)
                    ids = boxes.id.cpu().numpy().astype(int) if boxes.id is not None else [None] * len(boxes)

                    keep = []
                    for i, cls_id in enumerate(cls_ids):
                        class_name = names[cls_id] if cls_id < len(names) else ""
                        if class_name in TARGET_CLASSES:
                            keep.append(i)
                            # à¸šà¸±à¸™à¸—à¸¶à¸à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ object
                            if ids[i] is not None:
                                track_memory[ids[i]] = {
                                    'last_seen': current_time,
                                    'box': boxes.xyxy[i].cpu().numpy()
                                }

                    if keep:
                        result.boxes = result.boxes[keep]
                    else:
                        result.boxes = None

            # à¸¥à¸š object à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸›à¸™à¸²à¸™à¹€à¸à¸´à¸™ 5 à¸§à¸´à¸™à¸²à¸—à¸µ
            track_memory = {
                k: v for k, v in track_memory.items()
                if current_time - v['last_seen'] < 15.0
            }

            # à¸§à¸²à¸”à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ
            output = frame.copy()
            if results[0].boxes is not None:
                boxes = results[0].boxes
                cls_ids = boxes.cls.cpu().numpy().astype(int)
                ids = boxes.id.cpu().numpy().astype(int) if boxes.id is not None else [None] * len(boxes)
                xyxy = boxes.xyxy.cpu().numpy()

                for i, box in enumerate(xyxy):
                    x1, y1, x2, y2 = box.astype(int)
                    class_name = model.names[cls_ids[i]]
                    object_id = ids[i]

                    # à¸§à¸²à¸”à¸à¸£à¸­à¸šà¸”à¹‰à¸§à¸¢à¹€à¸ªà¹‰à¸™à¸šà¸²à¸‡
                    color = get_color_by_class(class_name)
                    cv2.rectangle(output, (x1, y1), (x2, y2), color, 1)


                    label = f"{class_name}"
                    if object_id is not None:
                        label += f" ID#{object_id}"

                    # à¸§à¸²à¸” label
                    cv2.putText(output, label, (x1, y1 - 5),
                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)



            # à¹à¸ªà¸”à¸‡à¸œà¸¥
            cv2.imshow("YOLOv8 RTSP", output)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("ðŸ‘‹ à¸­à¸­à¸à¸ˆà¸²à¸à¹‚à¸›à¸£à¹à¸à¸£à¸¡à¹à¸¥à¹‰à¸§")
                break

            pipe.stdout.flush()

    finally:
        pipe.terminate()
        cv2.destroyAllWindows()
        print("âœ… à¸›à¸´à¸”à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ FFmpeg à¹à¸¥à¸°à¸«à¸™à¹‰à¸²à¸•à¹ˆà¸²à¸‡à¹à¸¥à¹‰à¸§")

if __name__ == "__main__":
    os.environ['FFREPORT'] = 'file=ffmpeg_errors.log'
    main()
